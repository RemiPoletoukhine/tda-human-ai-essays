{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rpole/miniconda3/envs/tda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to /home/rpole/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding the dataset from the paper  **ChatGPT Generated Text Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'chatgpt-generated-text-detection-corpus'...\n",
      "remote: Enumerating objects: 280, done.\u001b[K\n",
      "remote: Counting objects: 100% (280/280), done.\u001b[K\n",
      "remote: Compressing objects: 100% (280/280), done.\u001b[K\n",
      "remote: Total 280 (delta 6), reused 258 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (280/280), 241.07 KiB | 8.31 MiB/s, done.\n",
      "Resolving deltas: 100% (6/6), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/rexshijaku/chatgpt-generated-text-detection-corpus.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract titles of the essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chatgpt-generated-text-detection-corpus/full_texts/questions.txt') as f:\n",
    "    titles = [line.rstrip('\\n') for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2) Why do you think people attend college or university? Use specific reasons and examples to support your answer.',\n",
       " '3) Do you agree or disagree with the following statement? Parents are the best teachers. Use specific reasons and examples to support your answer.',\n",
       " '5) It has been said, “Not everything that is learned is contained in books.” Compare and contrast knowledge gained from experience with knowledge gained from books. In your opinion, which source is more important? Why?',\n",
       " '6) A company has announced that it wishes to build a large factory near your community. Discuss the advantages and disadvantages of this new influence on your community. Do you support or oppose the factory? Explain your position.',\n",
       " '7) If you could change one important thing about your hometown, what would you change? Use reasons and specific examples to support your answer.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to dataframe while regex-ing the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract indices from the beginning of each title\n",
    "indices = [int(title.split(' ')[0][:-1]) for title in titles]\n",
    "titles = [title.split(' ', 1)[1] for title in titles]\n",
    "\n",
    "# create a dataframe\n",
    "title_df = pd.DataFrame({'essay_id': indices, 'title': titles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Why do you think people attend college or univ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Do you agree or disagree with the following st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>It has been said, “Not everything that is lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>A company has announced that it wishes to buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>If you could change one important thing about ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id                                              title\n",
       "0         2  Why do you think people attend college or univ...\n",
       "1         3  Do you agree or disagree with the following st...\n",
       "2         5  It has been said, “Not everything that is lear...\n",
       "3         6  A company has announced that it wishes to buil...\n",
       "4         7  If you could change one important thing about ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('chatgpt-generated-text-detection-corpus/full_texts/human/'):\n",
    "    with open(f'chatgpt-generated-text-detection-corpus/full_texts/human/{file}') as f:\n",
    "        a = f.read()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting human written essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_essay(author):\n",
    "    \"\"\"\n",
    "    Function to get the essays of a given author.\n",
    "    \n",
    "    Parameters:\n",
    "    author (str): the author of the essays\n",
    "    \n",
    "    Returns:\n",
    "    file_ids (list): the ids of the essays\n",
    "    essays (list): the essays of the author tokenized into sentences\n",
    "    \"\"\"\n",
    "    file_ids = []\n",
    "    essays = []\n",
    "    for file in os.listdir(f'chatgpt-generated-text-detection-corpus/full_texts/{author}/'):\n",
    "        with open(f'chatgpt-generated-text-detection-corpus/full_texts/{author}/{file}') as f:\n",
    "            file_ids.append(int(file.split('.')[0]))\n",
    "            sentences = nltk.tokenize.sent_tokenize(f.read().replace('\\n', ' '))\n",
    "            essays.append(sentences)\n",
    "    \n",
    "    return file_ids, essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the essays of the human author\n",
    "human_ids, human_essays = get_essay('human')\n",
    "# get the essays of the chatgpt\n",
    "machine_ids, machine_essays = get_essay('chatgpt')\n",
    "# create the corresponding dataframes\n",
    "human_df = pd.DataFrame({'essay_id': human_ids, 'sentence': human_essays, 'sentence_id': [[*range(len(essay))] for essay in human_essays]}).explode(['sentence', 'sentence_id'])\n",
    "machine_df = pd.DataFrame({'essay_id': machine_ids, 'sentence': machine_essays, 'sentence_id': [[*range(len(essay))] for essay in machine_essays]}).explode(['sentence', 'sentence_id'])\n",
    "# set the corresponding author columns\n",
    "human_df['author'] = 'human'\n",
    "machine_df['author'] = 'chatgpt'\n",
    "# merge the two dataframes\n",
    "df = pd.concat([human_df, machine_df]).reset_index(drop=True)\n",
    "# set the embedding_id column based on the author, essay_id and sentence_id\n",
    "df['embedding_id'] = df.groupby(['author', 'essay_id', 'sentence_id'], sort=False).ngroup()\n",
    "# add the correspoding topic of the essay\n",
    "df = df.merge(title_df, on='essay_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>author</th>\n",
       "      <th>embedding_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>This question of whether or not to give the st...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Many teachers assign homework to students ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>Of course, doing homework will scare our leisu...</td>\n",
       "      <td>1</td>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "      <td>Many teachers assign homework to students ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>So personally, I would prefer to do homework e...</td>\n",
       "      <td>2</td>\n",
       "      <td>human</td>\n",
       "      <td>2</td>\n",
       "      <td>Many teachers assign homework to students ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>There are numerous reasons why I think that da...</td>\n",
       "      <td>3</td>\n",
       "      <td>human</td>\n",
       "      <td>3</td>\n",
       "      <td>Many teachers assign homework to students ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>The main reason is daily homework can help stu...</td>\n",
       "      <td>4</td>\n",
       "      <td>human</td>\n",
       "      <td>4</td>\n",
       "      <td>Many teachers assign homework to students ever...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id                                           sentence sentence_id  \\\n",
       "0        70  This question of whether or not to give the st...           0   \n",
       "1        70  Of course, doing homework will scare our leisu...           1   \n",
       "2        70  So personally, I would prefer to do homework e...           2   \n",
       "3        70  There are numerous reasons why I think that da...           3   \n",
       "4        70  The main reason is daily homework can help stu...           4   \n",
       "\n",
       "  author  embedding_id                                              title  \n",
       "0  human             0  Many teachers assign homework to students ever...  \n",
       "1  human             1  Many teachers assign homework to students ever...  \n",
       "2  human             2  Many teachers assign homework to students ever...  \n",
       "3  human             3  Many teachers assign homework to students ever...  \n",
       "4  human             4  Many teachers assign homework to students ever...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Little sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique authors: ['human' 'chatgpt']\n",
      "Number of unique essay id: 126\n",
      "Number of essays per author: \n",
      " author\n",
      "chatgpt    126\n",
      "human      126\n",
      "Name: essay_id, dtype: int64\n",
      "Number of sentences: 4424\n",
      "Number of titles: 126\n",
      "Number of sentences per author: \n",
      " author\n",
      "human      2582\n",
      "chatgpt    1842\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Unique authors:', df['author'].unique())\n",
    "print('Number of unique essay id:', len(df['essay_id'].unique()))\n",
    "print('Number of essays per author: \\n', df.groupby('author')['essay_id'].nunique())\n",
    "print('Number of sentences:', len(df))\n",
    "print('Number of titles:', len(df['title'].unique()))\n",
    "print('Number of sentences per author: \\n', df['author'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "df.to_csv('essay_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentences are embedded in the script ``get_embeddings.py``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the obtained embeddings\n",
    "sentence_embeddings = np.load('sentence_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4424, 4096)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogn_bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
